\documentclass{beamer}
\usepackage{../common_slides}


\title{Part-of-Speech Tagging \\ + \\ Neural Networks}
\date{}
\author{CS 287}
\begin{document}

\begin{frame}{Review: Network}
  
\end{frame}

\begin{frame}{Word}
  Given the input ``The dog walked to the'' 
  We classify ``walked'' as a NN as opposed 
  to a VP, in a two-layer ReLU network with 
   a hinge-loss. 
   
   What is the maximum number of parameters that 
   receive an update?

   
  
  Is classified incorrectly as 
  If we have two-layer network 

\end{frame}


\begin{frame}{Answer: }
  $\boldW^2 = 2$ 

  $\boldW^1 = $ full  

  $\boldW^0 = 5$  
  

\end{frame}

\end{document}