{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--assignment and printing \n",
    "\n",
    "a, b = 24, \"tacos\" -- can assign tuple-style, like in python \n",
    "c = 'please' -- can enclose string literals in single or double quotes\n",
    "print(a,b,c,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- string concatenation\n",
    "\n",
    "d = b .. ', ' .. c\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " -- syntax similar to MATLAB\n",
    "print(2*a, a^2, a%2, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- note that all numbers are implicitly floats/doubles!\n",
    "print(a/7, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- if you want to ensure you get something integral, use math.ceil or math.floor\n",
    "print(math.floor(a/7), math.ceil(a/7), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- some other useful math functions\n",
    "print(math.min(1,22,44), math.max(1,22,44), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- while loops are enclosed in while-do-end blocks\n",
    "i = 1\n",
    "while i < 3 do\n",
    "    print(i)\n",
    "    i = i + 1 -- N.B. no 'i += 1' or 'i++' syntax in Lua \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- for-loops iterate over a range of numbers, INCLUSIVE!\n",
    "for i = 3, 5 do\n",
    "    print(i)\n",
    "end\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- like in python, you can specify the step size with a 3rd loop argument\n",
    "for i = 10, 1, -4 do\n",
    "    print(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- conditional statements go in if-then-elseif-else-end blocks\n",
    "val = 24\n",
    "\n",
    "if val == 0 then\n",
    "    print(\"zero!\")\n",
    "elseif val%2 == 0 then\n",
    "    print(\"even and nonzero!\")\n",
    "elseif val ~= 13 then           -- N.B. Lua uses '~=' to mean '!='; also works for strings!\n",
    "    print(\"odd and not 13!\")\n",
    "else\n",
    "    print(\"everything else!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truth and Falsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- nil and false evaluate to false\n",
    "a, b =  nil, false\n",
    "\n",
    "-- everything else evaluates to true\n",
    "c, d = \"taco\", 0\n",
    "\n",
    "if a or b then\n",
    "    print(\"first!\")\n",
    "elseif c and d then\n",
    "    print(\"second!\")\n",
    "else\n",
    "    print(\"third!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- 'and' and 'or' have interesting side effects; allow for 'ternary if' as follows:\n",
    "val2 = a and 1 or 2 -- a is falsey, so we get 2\n",
    "print(val2, \"\\n\")\n",
    "\n",
    "val3 = c and 3 or 4 --  c is truthy, so we get 3\n",
    "print(val3, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- local vs global variables\n",
    "\n",
    "var = 22 -- global\n",
    "\n",
    "function f1()\n",
    "    local var = 33 -- N.B. local variables generally lead to faster code! \n",
    "    return var + 1\n",
    "end\n",
    "\n",
    "print(f1(),\"\\n\")\n",
    "\n",
    "function f2()\n",
    "    return var + 1\n",
    "end\n",
    "\n",
    "print(f2(),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- default and extra arguments\n",
    "\n",
    "function encodeDigits(a,b,c)\n",
    "    local a = a or 0 -- common convention for specifying default args\n",
    "    local b = b or 0\n",
    "    local c = c or 0\n",
    "    assert(a >= 0 and a < 10)\n",
    "    assert(b >= 0 and b < 10)\n",
    "    assert(c >= 0 and c < 10)    \n",
    "    return a*1 + b*10 + c*100\n",
    "end\n",
    "\n",
    "print(encode_digits(1,2,3),\"\\n\") -- no defaults used\n",
    "print(encode_digits(2),\"\\n\") -- defaults for b and c used\n",
    "print(encode_digits(nil,2),\"\\n\") -- defaults for a and c used\n",
    "print(encode_digits(),\"\\n\") -- all defaults used\n",
    "print(encode_digits(1,2,3,4),\"\\n\") -- 4th argument ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- returning multiple values\n",
    "\n",
    "function divWithRemainder(a,b)\n",
    "    return math.floor(a/b), a%b\n",
    "end\n",
    "\n",
    "d,r = divWithRemainder(10,3)\n",
    "print(d,r)\n",
    "\n",
    "-- (function stuff outside the scope of this tutorial: functions are first class objects, closures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables (more or less the only native data-structure provided by Lua)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tables as Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- tables can be used as hash-based associative arrays (like python dictionaries)\n",
    "t1 = {} -- construct an empty table\n",
    "t1[\"one\"] = 1\n",
    "t1[\"two\"] = 2\n",
    "t1[3] = \"three\"\n",
    "print(t1, \"\\n\")\n",
    "\n",
    "t2 = {[\"one\"]=1, [\"two\"]=2, [3]=\"three\"} -- constructing a table literal\n",
    "print(t2, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- can access string attributes either with brackets, or with dot notation\n",
    "print(t2[\"one\"], t2[3], \"\\n\")\n",
    "print(t2.one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- iterating over key, value pairs\n",
    "for k,v in pairs(t1) do\n",
    "    print(k,v)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- remove elements from dictionaries by setting to nil\n",
    "t1[\"one\"] = nil\n",
    "print(t1,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tables as (ordered) arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- when a table uses only integer keys 1..n, it can also function as an array!\n",
    "-- N.B. Tables (and tensors) are 1-indexed!!!\n",
    "arr = {} -- construct an empty array\n",
    "arr[1] = \"one\"\n",
    "arr[2] = \"two\"\n",
    "arr[3] = \"three\"\n",
    "print(arr,\"\\n\")\n",
    "\n",
    "arr2 = {\"one\", \"two\", \"three\"} -- construct an array literal\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- can get the length of an array by prepending with '#'\n",
    "print(#arr,\"\\n\") \n",
    "\n",
    "--N.B. '#' only works with array-style tables (and not with dictionary-style tables)\n",
    "  -- If you want to get the size of a dictionary in constant time, you need to store it somewhere; gross!\n",
    "ugh = {[\"one\"]=1, [\"two\"]=2}\n",
    "print(#ugh,\"\\n\") -- misleading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- instead to using integer keys to index, can also append to table as follows\n",
    "arr3 = {}\n",
    "table.insert(arr3,\"one\") -- equivalent to t[#t+1] = \"one\"\n",
    "table.insert(arr3,\"two\")\n",
    "print(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- can iterate over an array in order as follows\n",
    "for i, el in ipairs(arr2) do -- ipairs() is like enumerate() in python\n",
    "    print(i, el)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- to remove elements from array, use table.remove (which is inefficient)\n",
    "table.remove(arr2,2)\n",
    "print(t,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--[[ Tensors are multi-dimensional generalizations of arrays/matrices, and are the primary data-structure provided\n",
    "     by Torch (just as arrays are the primary data-structure providedy by Numpy). Tensors are great, and anytime  \n",
    "     you can use them you probably should.\n",
    "\n",
    "     Also check out https://github.com/torch/torch7/blob/master/doc/tensor.md for documentation on Tensor objects,\n",
    "     and https://github.com/torch/torch7/blob/master/doc/maths.md for documentation on mathematical operations\n",
    "     defined on Tensors\n",
    "--]]\n",
    "\n",
    "-- here are some ways of constructing Tensors (of different sizes and dimensions)\n",
    "A = torch.Tensor(3,3) -- an empty 3x3 Tensor (initialized with garbage)\n",
    "B = torch.zeros(3,3,2) -- 3x3x2 Tensor initalized with zeros\n",
    "C = torch.ones(3,1,3)  -- 3x1x3 Tensor initialized with ones\n",
    "D = torch.randn(2) -- 2-vector (still a Tensor) initialized with standard gaussian noise\n",
    "E = torch.rand(1,1,1,1)  -- 1x1x1x1 Tensor initialized with uniform noise\n",
    "F = torch.Tensor({{1,1},{2,2}}) -- 2x2 literal tensor\n",
    "\n",
    "print(A,\"\\n\")\n",
    "print(B,\"\\n\")\n",
    "print(C,\"\\n\")\n",
    "print(D,\"\\n\")\n",
    "print(E,\"\\n\")\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- by default Tensor() gives you a \"real\" Tensor, and you can set whether \"real\" defaults to float or double.\n",
    "-- if you want to explicitly pick one, there are also specialized constructors\n",
    "A = torch.FloatTensor(3,3)\n",
    "print(A,\"\\n\")\n",
    "B = torch.LongTensor(3,3) -- N.B. LongTensors hold integers and are very important; we use them to store indices\n",
    "print(B,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- some important ways to get Tensor metadata\n",
    "A = torch.randn(2,3)\n",
    "print(A:dim()) -- number of dimensions\n",
    "print(A:size()) -- size of each dimension\n",
    "print(A:nElement()) -- total number of element\n",
    "print(A:isContiguous()) -- does Tensor address a contiguous block of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Views on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- can \"view\" a tensor in a different shape without doing any copy\n",
    "a = torch.range(1,6) -- numbers 1 thru 6\n",
    "print(a,\"\\n\")\n",
    "A = a:view(2,3) -- the ':' notation implicitly adds 'self' to a function call (when defined on objects)\n",
    "print(A)\n",
    "\n",
    "-- note view() reshapes along rows (like C and numpy), not along columns (like fortran and R) \n",
    "B = A:view(3,2)\n",
    "print(B,\"\\n\")\n",
    "\n",
    "-- note a, A, and B address the same memory!\n",
    "B:zero() -- zeroes out a tensor\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Sub-Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- index notation allows you to index along the first dimension\n",
    "A = torch.range(1,6):view(2,3)\n",
    "firstRow = A[1]\n",
    "print(A,\"\\n\")\n",
    "print(firstRow)\n",
    "\n",
    "-- this does no memory copy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- select() allows you to index along any dimension\n",
    "firstCol = A:select(2,1) -- select()'s first argument is the desired dimension\n",
    "print(firstCol)\n",
    "-- also does no memory copy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- instead of accessing a single index, can narrow a Tensor along a chosen dimension\n",
    "firstRow = A:narrow(1,1,1) -- arguments are dim, startIdx, length along dim to extract\n",
    "last2Cols = A:narrow(2,2,2)\n",
    "print(firstRow,\"\\n\")\n",
    "print(last2Cols)\n",
    "\n",
    "-- this also addresses SAME memory as in original tensor\n",
    "last2Cols:zero()\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- while narrow() calls can be chained, can also use sub() to narrow along first 4 dimensions\n",
    "A = torch.range(1,6):view(2,3)\n",
    "firstRow = A:sub(1,1) -- arguments are start and stop idx (inclusive) for each dimension (up to 4)\n",
    "last2Cols = A:sub(1,2,2,3) -- using start and stop indices for first two dimensions here\n",
    "bottomRight = A:sub(2,2,3,3)\n",
    "\n",
    "print(firstRow,\"\\n\")\n",
    "print(last2Cols,\"\\n\")\n",
    "print(bottomRight,\"\\n\")\n",
    "\n",
    "-- as above, this addresses same memory as original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- instead of using sub() and narrow(), can also specify ranges by indexing with tables\n",
    "firstRow = A[{{1,1},{}}] -- expects table of range-tables, 1 for each dimension; empty table means everything\n",
    "last2Cols = A[{{},{2,3}}] -- note similarity to sub()\n",
    "bottomRight = A[{{2,2},{3,3}}]\n",
    "\n",
    "print(firstRow,\"\\n\")\n",
    "print(last2Cols,\"\\n\")\n",
    "print(bottomRight,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- we can select non-contiguous items along the first dimension using index()\n",
    "A = torch.range(1,9):view(3,3)\n",
    "idxs = torch.LongTensor({1,3}) -- indices are often required to be stored in LongTensors\n",
    "firstAndThirdRows = A:index(1,idxs) -- first argument is the dimension\n",
    "print(A,\"\\n\")\n",
    "print(firstAndThirdRows,\"\\n\")\n",
    "\n",
    "--N.B. index() does a memory copy!\n",
    "firstAndThirdRows:zero()\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- can also update a matrix sparsely with indexAdd()\n",
    "A = torch.zeros(3,3)\n",
    "idxs = torch.LongTensor({1,3})\n",
    "U = torch.randn(2,3)\n",
    "A:indexAdd(1,idxs,U) -- U must be of dimension idxs:size(1) x A:size(2)\n",
    "print(A)\n",
    "-- there's also indexFill() and indexCopy(); see the documentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-place Operations vs. Copying Operations (Very Important!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- for most (mathematical) operations defined on tensors, you will have a choice between allocating new memory for\n",
    "-- the result of the operation, or placing the result in some already-allocated tensor.\n",
    "-- for example, let's consider taking the element-wise absolute value of a tensor A\n",
    "A = torch.randn(3,3)\n",
    "\n",
    "-- if we want to allocate a NEW tensor B s.t. B = abs(A), we do the following\n",
    "B = torch.abs(A) -- in general, using torch.f to call a function f on a tensor will allocate new memory\n",
    "\n",
    "-- let's make sure A has not changed\n",
    "print(A,\"\\n\")\n",
    "print(B,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- suppose instead we have some tensor C lying around that we want to use to store abs(A)\n",
    "C = torch.Tensor(3,3)\n",
    "-- we can use C to store abs(A) as follows\n",
    "C:abs(A) -- recall the ':' notation is short-hand for passing 'self' to a function defined on an object\n",
    "         -- in general, calling X:f(args) will use X's memory to store the result of f(args)\n",
    "print(C,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- often it is convenient to use a tensor to store its own result\n",
    "A:abs()\n",
    "-- now A has changed\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- the in-place/copying distinction is important for 2 reasons:\n",
    "-- 1) doing in-place operations is generally much faster than allocating memory repeatedly (e.g., in a loop)\n",
    "-- 2) on the other hand, easy to mess up your data by accidentally doing things in-place\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- many useful elementwise operations are defined, and (as above), can be used in-place or not\n",
    "torch.sqrt(A)\n",
    "A:sqrt()\n",
    "torch.tanh(A)\n",
    "A:tanh()\n",
    "-- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row or Column-wise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- can take sum, mean, stddev of rows or columns as follows\n",
    "A = torch.randn(2,3)\n",
    "colSums = A:sum(1) -- sum along first dimension; can also do A:mean(1), A:std(1), etc\n",
    "rowSums = A:sum(2) -- sum along second dimension; can also do A:mean(2), A:std(2), etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- torch combines max and argmax() \n",
    "a = torch.range(2,6)\n",
    "maxval, argmax = a:max(1) -- argument specifies dimension\n",
    "print(maxval, argmax)\n",
    "-- can also take min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    " linear algebra\n",
    " hdf5\n",
    " maybe classes\n",
    " have them do an SGD example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
